# Разработка приложения для 3D моделирования в VR на основе hand tracking
Ключевые слова: 3d-моделирование, hand-tracking, ...

## Аннотация

---

## Введение

В настоящее время активно развивается проектирование объектов в цифровом трехмерном пространстве — 3D моделирование. Одной из проблем в этой области является процесс взаимодействия человека и машины. Несмотря на то, что в повседневной жизни для взаимодействия с окружающим миром в большинстве случаев используются руки, при работе с 3D-моделирующими приложениями (Maya, Blender, ZBrush, 3Ds Max...) человек вынужден использовать стандартные устройства ввода. В связи с этим у начинающих пользователей приложений для 3D моделирования возникают сложности с понятием пользовательского интерфейса.

Из вышесказанного возникает идея управлять 3D моделирующими приложениями исключительно при помощи жестов. Поэтому цель данной статьи заключается в том, чтобы разработать приложение для 3D моделирования в VR при помощи hand tracking.

Для реализации поставленной цели необходимо решить следующие задачи:
- исследовать существующие решения по 3D моделированию при помощи hand tracking;
- реализации приложения для 3D моделирования при помощи hand tracking.

Hand tracking можно осуществлять при помощи различных средств, например, контроллеров для игровых приставок или очков дополненной реальности, реагирующих на движение рук. Однако при использовании таких устройств сковываются движения, может ощущаться дискомфорт. Альтернативой можно считать устройства для отслеживания жестов, работающие при помощи специальных камер, из которых в режиме реального времени можно извлекать данные о положении рук и пальцев. 

Объектом исследования данной работы является 3D моделирование в VR при помощи hand tracking. Предмет исследования - интеграция Unity и Leap Motion для разработки приложения для 3D моделирования в VR при помощи hand tracking.

## Обзор существующих решений

Для обзора существующих решений используются технологии, позволяющие моделировать виртуальные 3D объекты без помощи стандартных устройств пользовательского ввода, опираясь на движения рук в пространстве и жесты рук. 
Основные требования к функционалу: возможность изменять положение модели (перемещать и/или вращать и/или изменять масштаб) и возможность изменять форму модели / создавать модель с нуля.

### <Аналог1>

Первая технология была предложена Хироаки Нишино в 1998 году - 3D моделирование объектов с использованием пространственных и пиктографических жестов [1]. Для ее использования необходимы бимануальные жестовые перчатки, очки с затвором и 200-дюймовый стереоскопический экран. Для создания модели необходимо подготовить несколько примитивных фигур, объединить эти примитивы, чтобы сформировать «грубую» форму и провести ее деформацию для корректировки. Присутствует возможность вращать объекты, захватывая их двумя руками, и регистрировать предпочитаемые жесты перед использованием технологии.

### <Аналог2>

В 2001 году Стивеном Школьном была предложена еще одна технология - рисование органических поверхностей в воздухе с помощью рук [2]. При помощи магнитного инструмента, прикрепленного к рукам, пользователь может рисовать поверхности в воздухе над «отзывчивым» рабочим столом. При помощи очков со стереоскопическим затвором над столом можно увидеть получаемую модель.
Пользователи могут перемещать объекты с помощью кухонных щипцов, оснащенных магнитными трекерами и датчиками (чтобы определять, когда они закрыты). Когда щипцы закрыты, пользователь может захватить объект и переместить его в виртуальное трехмерное пространство. Второй щипец можно использовать вместе с первым для масштабирования объектов (раздвигая с сдвигая щипцы по отношению друг к другу).

### <Аналог3>

Кевин Т. Макдоннелл и Влодарчик в 2001 году разработали систему моделирования, которая позволяет деформировать упругую виртуальную глину, используя тактильный инструмент взаимодействия, обеспечивая реалистичный опыт скульптинга [3]. Пользовательский интерфейс состоит из тактильного устройства PHANToM, стандартной 2D-мыши и экранных элементов управления графическим интерфейсом.
Один из способов использования тактильного инструмента состоит в том, чтобы деформировать модель так же, как при лепке из глины. Геометрические инструменты используются для выбора ячеек в объекте с помощью трехмерного курсора для их вдавливания, разделения или выдавливания. Физические инструменты предназначены для формирования объекта путем редактирования физических свойств, таких как точки массы и распределение жесткости.

### <Аналог4>

Цзя Шэн в 2006 году предложил интерфейс для виртуального трехмерного моделирования с использованием губки [4]. Данное приложение способно манипулировать 3D-моделями, используя губку в качестве инструмента. Основой является технология отслеживания движения на основе камеры для отслеживания пассивных маркеров на пальцах и губке, как показано на рисунке.

### <Аналог5>

Freeform 3 - приложение, разработанное для использования с Leap Motion (небольшое устройство длиной менее 8 см, представляющее собой оптическую систему слежения на основе стереозрения) [5]. В данном приложении 3D объект представляется вращающаяся форма из глины, стекла или пластика помещается на невидимый стол. Пользователи могут использовать свой палец в качестве инструмента для изменения формы. Для смены режимов работы данного приложения (выбор сцены, материала, вращения) предназначены иконки, располагающиеся по краям окна. 
 
### Сравнение аналогов

1. Манипулирование дополнительными устройствами.

Критерий обозначает необходимость во время работы держать специальные устройства в руках или надевать на руки. Если такая необходимость присутствует, то движения человека могут быть скованы либо человек может ощущать дискомфорт.

"+" означает, что требуется манипулировать дополнительными устройствами во время работы;

"-" означает, что не требуется.

"-" - "хорошо"; "+" - "плохо".

2. Необходимость работать с контекстным меню для смены режимов работы.

Критерий обозначает то, что в процессе моделирования не нужно отвлекаться на то, чтобы изменить какие-либо режимы/параметры работы где-нибудь в боковом меню. Это способствует уменьшению реалистичности, что является одним из главных требований к технологии VR.

"+" означает, что для смены режимов требуется работать с контекстным меню;

"-" означает, что не требуется.

"+" - "плохо"; "-" - "хорошо".

3. Доступность/цена необходимых устройств.

Критерий обозначает наличие для покупки в интернет-магазинах устройств, необходимых для 3D моделирования. Если возможность приобрести устройство есть, рассматривается еще и его цена. Важность критерия обоснована тем, что без возможности приобрести необходимые устройства либо при слишком высокой цене технология/метод не может получить широкого распространения.

"+/число$" означает, что устройство можно приобрести за цену, указанную после "/";

"-" означает, что устройство в свободном доступе найти нельзя.

"+/число$" - "хорошо"; "-2 - "плохо". Чем ниже цена, тем лучше.

4. Погрешность распознавания положения.

Критерий обозначает погрешность распознавания устройством, используемым аналогом, положения руки/маркера.

Чем больше для аналога погрешность, тем меньше точность процесса 3D-моделирования из-за некорректного распознавания жестов и положений рук.

Сравнение рассмотренных аналогов по вышеперечисленным критериям представлено в табл. 1.

Таблица 1 - сравнение аналогов

|     | аналог 1  | аналог 2 | аналог 3 | аналог 4 | аналог 5 |
| --- | --- | --- | --- | --- | --- |
| **манипулирование дополнительными устройствами** | + | + | + | + | - |
| **необходимость работать с контекстным меню для смены режимов работы** | - | - | + | - | + | 
| **доступность/цена необходимых устройств** | - | - | +/2400$ | - | +/90$ |
| **погрешность распознавания положения** |	2,54 см |	0,4 см |	0,26 см |	0,02 см |	0,012 см |

Цены устройств для аналогов 3 и 5 взяты из источников [7] и [8]. 
Погрешности для аналогов 1-5 взяты из источников [8], [9], [10], [11], [12].

Устройство для аналога 6 пока недоступно для покупки в связи с недавним анонсированием (май 2019 года).

В результате сравнения было выявлено, что у каждой из рассмотренных технологий есть слабые стороны в отношении рассмотренных критериев. Однако приложение Free Form показывает лучшие результаты среди рассмотренных аналогов (побеждает по двум критериям из трех): за разумную цену купить оборудование можно только для Free Form, что означает, что для рядового пользователя доступно в основном только это приложение; при его использовании не нужно использовать какие-либо датчики либо держать специальные устройства в руках, так что руки полностью свободны (ограничены только пространством, в котором камеры улавливают движения рук).

Это означает, что при разработке приложения для 3D моделирования при помощи hand tracking необходимо взять лучшие стороны от Free Form (использовать устройство Leap Motion, чтобы соответствовать критериям "манипулирование дополнительными устройствами" и  "доступность/цена необходимых устройств"), но постараться избежать необходимости работать с контекстным меню для смены режимов работы (всю работу выполнять только при помощи специальных жестов).

## Выбор метода решения

На основании обзора аналогов было определено, что должно собой представлять решение задачи и какими основными качествами оно должно обладать.

Решение должно представлять собой разработанное приложение для 3D моделирования в VR при помощи hand tracking.

Hand tracking должен осуществляться при помощи контроллера Leap Motion по следующим причинам:

- Отслеживание рук и жестов через обычную веб-камеру возможно, но имеет малую точность и скорость по сравнению с решениями, использующими дополнительные устройства для отслеживания рук, поэтому не распространено для задачи 3D моделирования в VR. Поэтому необходимо использование специального устройства для отслеживания жестов рук.
- Leap Motion - самое доступное для покупки устройство среди рассмотренных аналогов, т.е. его можно приобрести на официальном сайте за самую низкую цену по сравнению с устройствами, необходимыми для работы рассмотренных аналогов.
-Leap Motion относительно рассмотренных аналогов удобно в исспользовании: для взаимодействия с ним нужно только подключить его к компьюьеру, необходимость держать в руках какие-либо дополнительные датчики либо устройства (или прикреплять их к рукам) отсутствует.
- Leap Motion из устройств рассмотренных аналогов имеет меньшую погрешность распознавания положения.

В отличие от Free Form, где hand tracking также реализован при помощи Leap Motion, в рассматриваемом решении работа пользователя, связанная с 3D моделированием, должна осуществляться только при помощи жестов, т.е. без необходимости менять режимы работы в контекстных меню. В таком случае управление будет более интуитивно понятно, не будет необходимости изучать все возможности интерфейса.

Основные требования к программе остаются такими же, как при выборе аналогов для сравнения: необходимо, чтобы была возможность изменять положение объекта в пространстве (вращать, перемещать, масштабировать) и изменять форму объекта.

## Описание метода решения
### Используемые технологии
В предыдущем разделе было решено использовать контроллер Leap Motion для пользовательского ввода, на основании чего выбирались используемые технологии. 

На сайте Leap Motion указано, что возможна VR интеграция с Unity и Unreal, и, так как для решения поставленной задачи больше подходит среда разработки Unity в связи с тем, что нет необходимости использовать высококачественные графические эффекты и для Unreal требуется высокая вычислительная мощность, выбор был остановлен на Unity. 

Сама интеграция Leap Motion и Unity осуществляется при помощи ресурса Leap Motion Core Assets. Он позволяет проекту Unity получить данные из фреймов, в которых Leap Motion API хранит атрибуты для рук, пальцев, костей и суставов пользователя. Эти данные используются в качестве пользовательского ввода.

### Сценарий использования
Чтобы рассмотреть, как пользовательский ввод будет интерпретироваться программой, необходимо определить сценарий использования приложения.

После запуска приложения перед пользователем возникает сцена со сферой в центре, которая обляется объектом, с которым пользователь будет взаимодействовать. Для взаимодействия пользователю необходимо поместить руки/руку над подключенным контроллером Leap Motion на высоте 15 см - на экране появится изображение рук/руки. Работа со сферой может осуществляться, пока руки в пределах видимости контроллера, т.е. отображаются на экране. Рассмотрим действия пользователя, необходимые для взаимодействия с объектом.

1. Изменение формы.
Для того, чтобы изменить форму объекта, пользователю необходимо поднести к поверхности объекта правую руку, соединить указательный и большой пальцы, а затем, не изменяя жеста, перемещать руку в пространстве в то положение, в котором должна оказаться выбранная точка для деформации объекта. После этого пальцы следует разъединить. В результате произойдет деформация сетки объекта и изменится его форма.

2. Масшабирование.
Для того, чтобы изменять размер объекта на сцене, пользователю необходимо поместить обе руки в область видимости контроллера, сжать их в кулаки, и уменьшать расстояние между ними по оси 0Х, чтобы уменьшить объект, или увеличивать расстояние между руками, чтобы увеличить объект. Для прекращения масштабирования кулаки надо разжать.

3. Перемещение.
Для того, чтобы перемещать объект на сцене, пользователю необходимо поместить левую руку в объект, сжать в кулак и перемещать руку в пространстве. Чтобы закончить перемещение объекта, кулак надо разжать.

4. Вращение.
Для вращения объекта также используется левая рука. Пользователю необходимо соединить указательный и большой пальцы (как для изменения формы объекта) и перемещать их в пространстве. Процесс вращения происходит аналогично вращению глобуса, только не вокруг оси, а вокруг центральной точки.

### Особенности реализации реализации (основные проблемы интеграции и их решение)
Рассмотрев, как приложение должно работать с точки зрения пользователя, можно приступить к описанию основных особенностей реализации.

1. Непрерывное отслеживание рук.
Пользовательский ввод должен постоянно осуществляться, и, соответственно, нужно обеспечить непрерывное поступление данных от Leap Motion API. Для этого в программе в методе Update() необходимо запрашивать обновленные данные от Frame.

2. Координаты.
Для всех решаемых задач пользовательского ввода важно пространственное положение рук/пальцев, однако было обнаружено, что системы координат Leap Motion и Unity не совпадают. Это связано с тем, что контроллер предоставляет координаты в миллиметрах реального мира в системе отсчета Leap Motion.

Для перевода координат с фрейма Leap Motion в систему координат Unity было решено использовать объект InteractionBox. Он представляет собой прямоугольную призму и предоставляет нормализованные координаты для рук и пальцев при помощи метода NormalizePoint (Vector position). Метод преобразует координаты Leap Motion в координаты в диапазоне [0; 1], так что минимальное значение InteractionBox отображается на 0, а максимальное значение InteractionBox отображается на 1. После этого координаты необходимо лишь "растянуть" на всю ширину InteractionBox.

Последним шагом для приведения координат Leap Motion к координатам Unity является отражение оси z, т.е. домножение всех z-координат на -1. Это связано с тем, что в контроллере используется правосторонняя система координат, а в Unity - левосторонняя.

На этом основные программные настройки контроллера завершены.

3. Отсутствие перепутывания жестов.
При разработке приложения большое внимание уделялось тому, чтобы жесты пользователя для разных взаимодействий не могли перепутаться и при этом оставались интуитивно понятными. Так, например, для вращения объекта и для деформации точки пользователь должен совершить один и тот же жест: соединить указательный и большой пальцы. 

Во избежание спутывания операций было решено использовать ввод левой и правой рукой четко разделенным. Для мониторинга того, какая рука в данный момент находится в кадре, необходимо в методе Update вызывать метод Frame.Hands.Count(), и в случае, если он возвращает 1, то есть говорит о том, что пользователь использует только одну руку, вызывать метод  Hand.IsLeft() для определения руки.

4. Захват точки.
При захвате пользователем точки на объекте для деформации модели сложно достигнуть того, чтобы координаты пальцев пользователя полностью совпадали с точкой, т.к. для этого точность движений пользователя должна составлять доли миллиметра.  Было решено использовать допустимые границы, определяющие близость расстояния пальцев пользователя до поверхности объекта и, если пользователь попадает в заданные границы, брать ближайшую точку.

Аналогичная ситуация с самим распознаванием жестов сведения большого и указательного пальцев (жест "pinch") и распознаванием жеста сжатия руки в кулак (жест "grab"). Устанавливаются допустимые границы 0.8, в которых данные жесты "засчитываются", при помощи методов Hand.GrabStrength() и Hand.PinchStrength(), которые возвращают число  в диапазоне [0; 1].

## Заключение

---

## Список литературы

---
